# Deeplog and LogAnomaly Models For Log Anomaly detection
Software-intensive systems produce lots of logs for troubleshooting purposes,  which can help engineers understand the systemâ€™s internal status and facilitate monitoring, administering, and troubleshooting of any system. 

Numerous deep learning models have been proposed for the automated detection of system anomalies using log data. However, the impracticality of collecting and labeling logs in real-world environments has prompted the exploration of unsupervised models.

This code comprises two log-based anomaly detection models adjusted to our own needs,  [Deeplog][1] and [LogAnomaly][2].

It's important to note that many log-based models are often evaluated on labeled datasets such as HDFS, BGL, Thunderbird, and Spirit. However, these models frequently lack open-source toolkits or code, making reproducibility challenging for developers. This project does not aim to replicate results from these papers, and consequently, the models employed on this project may differ from the original papers.


## Table of contents 
  1. [Dataset](#dataset)
  2. [Model details](#model-details)
  3. [Usage](#usage)
  4. [Development setup](#development-setup)
  5. [Task list](#task-list)
  6. [References](#references)

## Dataset


Log data is usually unstructured text messages where anomaly detection models comprend parsing as a step within their framework, there are several parsing techniques, however, here we do not deal with that. The data must be already parsed and formated as JSON objects. E.g:
 ``` 
{"_zl_timestamp": "1696149046000", 
"log_uuid":"80ad959d-5815-11ee-988e-cc483a4638dd_elacollector8da9fe5e9b2c42c7843bcdff5175e0435257320593532651", 
"SEVERITY": "success", 
"HOSTNAME": "gokul-l3c", 
"HOSTID": "27000000269125", 
"HOSTTYPE": "windows", 
"MESSAGE": "An attempt was made to duplicate a handle to an object.\r\n\r\nSubject:\r\n\t
    Security ID:\t\tS-1-5-18\r\n\tAccount Name:\t\tGOKUL-L3C$\r\n\tAccount Domain:\t\t
    WORKGROUP\r\n\tLogon ID:\t\t0x3E7\r\n\r\nSource Handle Information:\r\n\tSource Handle ID:\t0x12a8\r\n\tSource Process ID:\t0x160\r\n\r\n
    New Handle Information:\r\n\tTarget Handle ID:\t0x5b1c\r\n\tTarget Process ID:\t0x4", 
"TYPE": "security", 
"SOURCE": "microsoft-windows-security-auditing", 
"TASKCATEGORY": "handle manipulation", 
"EVENTID": "4690", 
"TIME": "1696149046061"}
 ``` 

In this case, this data do not contain event templates, so event ids are used instead. Adding to it, each JSON object can have less or more keys, thereby identify the common useful keys across all the datasets and use those keys in order to avoid error. 
These main keys we found at the moment are: **(EVENTID, SEVERITY, MESSAGE, log_uuid, _zl_timestamp)**.


## Model Details
Deeplog and LogAnomaly predict the next log event given preceding log sequences, thus requiring sequential vectors (as they utilize LSTM Models). Thus, both models use the index of log events (i.e., sequential and quantitative vectors) and ignore the semantic meaning of logs during the training phase.













[1]: https://dl.acm.org/doi/10.1145/3133956.3134015 
[2]: https://www.ijcai.org/proceedings/2019/658 
